{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6402875",
   "metadata": {},
   "source": [
    "# Lab 02 · HTTP Forms and Retry\n",
    "\n",
    "*This lab notebook provides guided steps. All commands are intended for local execution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49bc88",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- A robust fetch helper with retry logic is introduced.\n",
    "- A controlled React form is configured with loading and error feedback.\n",
    "- Friendly error messages are surfaced in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd98d1",
   "metadata": {},
   "source": [
    "## What will be learned\n",
    "- Retry helpers are structured for frontend HTTP calls.\n",
    "- Controlled form patterns in React are rehearsed.\n",
    "- Error boundaries in simple forms are practiced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36018592",
   "metadata": {},
   "source": [
    "## Prerequisites & install\n",
    "The following commands are intended for local execution.\n",
    "\n",
    "```bash\n",
    "cd ai-web/frontend\n",
    "npm install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079d9e27",
   "metadata": {},
   "source": [
    "\n",
    "### FastAPI service context\n",
    "\n",
    "#### Project modules at a glance\n",
    "- `app/main.py` instantiates `FastAPI()`, attaches middleware, and mounts routers that expose `/echo`, `/flaky-echo`, and AI-specific routes. [Docs: First Steps](https://fastapi.tiangolo.com/tutorial/first-steps/)\n",
    "- `app/routers/*.py` files group related path operations (echo, profiles, inference) with `APIRouter`, keeping HTTP contracts colocated with their dependencies. [Docs: Bigger Applications](https://fastapi.tiangolo.com/tutorial/bigger-applications/)\n",
    "- `app/schemas.py` (or per-router schema modules) defines request and response models with Pydantic so payloads are validated before network calls. [Docs: Request Body](https://fastapi.tiangolo.com/tutorial/body/)\n",
    "- `app/dependencies.py` centralizes shared resources: AI clients, caches, rate limiters, and database sessions that are injected into routes. [Docs: Dependencies](https://fastapi.tiangolo.com/tutorial/dependencies/)\n",
    "\n",
    "#### Dependency injection, validation, and error handling\n",
    "1. **Inject shared services** with `Depends` to supply configured AI providers or retry-aware HTTP clients. This keeps path operations small and testable. [Docs: Dependencies in path operation decorators](https://fastapi.tiangolo.com/tutorial/dependencies/dependencies-with-yield/)\n",
    "2. **Guard requests** by layering validation logic in Pydantic models (`Field` constraints, enums for model selection) so malformed prompts never reach third-party APIs. [Docs: Extra Data Types](https://fastapi.tiangolo.com/tutorial/extra-data-types/)\n",
    "3. **Translate failures** into `HTTPException` responses that surface actionable status codes and messages to the React UI. Use exception handlers to map provider timeouts into `503` responses that the retry helper can recognize. [Docs: Handling Errors](https://fastapi.tiangolo.com/tutorial/handling-errors/)\n",
    "4. **Instrument long tasks** with `BackgroundTasks` for actions like saving transcripts or emitting telemetry once inference completes. [Docs: Background Tasks](https://fastapi.tiangolo.com/tutorial/background-tasks/)\n",
    "5. **Document everything** via the automatic OpenAPI schema so teammates can inspect request/response shapes directly in `/docs`. [Docs: Interactive API docs](https://fastapi.tiangolo.com/features/#interactive-api-docs)\n",
    "\n",
    "#### How this supports AI endpoints\n",
    "- Async path operations let you await inference, embedding, or vector search calls without blocking other requests.\n",
    "- Dependency-injected providers make it easy to swap models (e.g., OpenAI, Anthropic, local models) or wrap them with retry/backoff logic.\n",
    "- Consistent error payloads (status code + message + optional retry-after metadata) give the frontend enough context to decide when to retry, alert, or escalate.\n",
    "\n",
    "### Vite-powered React environment refresher\n",
    "\n",
    "#### Dev tooling recap\n",
    "- Initialize the project with `npm create vite@latest frontend -- --template react` and install dependencies (`npm install`). [Docs: Getting Started](https://vitejs.dev/guide/)\n",
    "- Run `npm run dev` for hot module replacement while coding forms; run `npm run build && npm run preview` to validate production bundles.\n",
    "- Configure the dev server proxy in `vite.config.js` so `/api` points to `http://localhost:8000`, matching the FastAPI service. [Docs: Server Proxy](https://vitejs.dev/config/server-options.html#server-proxy)\n",
    "- Store secrets and backend URLs in `.env.local` using `VITE_` prefixes (e.g., `VITE_API_BASE_URL`). Access them in code via `import.meta.env`. [Docs: Env Variables](https://vitejs.dev/guide/env-and-mode.html)\n",
    "\n",
    "#### Organizing AI-friendly modules\n",
    "- Mirror backend routers by placing React features in `src/features/<domain>/` with colocated hooks (`useEchoForm.js`, `useProfileFetcher.js`).\n",
    "- Keep API helpers inside `src/lib/` such as `retry.js`, `apiClient.js`, and streaming utilities that wrap `fetch` with AbortController support.\n",
    "- Use React hooks (`useState`, `useEffect`, `useReducer`) to manage prompt inputs, loading flags, and streaming buffers. Reference the [React docs](https://react.dev/reference/react) for deeper hook usage.\n",
    "- Compose UI primitives in `src/components/` for buttons, toasts, and skeleton loaders so each AI workflow shares consistent feedback.\n",
    "- Track experiment flags (e.g., \"use streaming\", \"call fallback model\") with context providers or state libraries (Zustand, Redux Toolkit) when the app grows.\n",
    "\n",
    "#### Backend ↔ frontend toolchain overview\n",
    "| Layer | Key tool | Purpose for this lab |\n",
    "| --- | --- | --- |\n",
    "| Backend runtime | FastAPI + Uvicorn | Serves async echo routes, enforces validation, exposes OpenAPI docs |\n",
    "| Shared services | Dependency injection | Provides AI clients, caches, and retry-enabled HTTP wrappers |\n",
    "| Frontend dev server | Vite HMR proxy | Mirrors backend routes locally, handles env injection |\n",
    "| UI layer | React components + hooks | Collects form data, surfaces retries, renders AI responses |\n",
    "\n",
    "### AI request flow checklist\n",
    "1. **Define the FastAPI route**: confirm `app/routers/echo.py` (or similar) receives a validated model and raises `HTTPException` with descriptive messages for retryable failures.\n",
    "2. **Register dependencies and middleware**: ensure CORS, logging, and provider clients are available so retries are meaningful and observable.\n",
    "3. **Expose configuration**: add `.env` values for `API_BASE_URL`, AI model keys, and retry timing that both FastAPI and Vite can read.\n",
    "4. **Create or update the shared API utility**: in `src/lib/apiClient.js`, read `import.meta.env.VITE_API_BASE_URL`, attach headers, and export helpers consumed by `withRetry`.\n",
    "5. **Wire React forms to the helper**: in `src/App.jsx`, collect input, call `withRetry`, and map resolved data into component state while disabling submit buttons during attempts.\n",
    "6. **Iterate locally, then containerize**: run `uvicorn app.main:app --reload` alongside `npm run dev` to test the full round trip. Once stable, bake the same env vars into Docker or deployment pipelines for parity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7ef5f",
   "metadata": {},
   "source": [
    "## Step-by-step tasks\n",
    "### Step 1: Retry helper placement\n",
    "A retry helper is positioned under src/lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530801d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "lib = Path(\"ai-web/frontend/src/lib\")\n",
    "lib.mkdir(parents=True, exist_ok=True)\n",
    "(lib / \"retry.js\").write_text('''export async function withRetry(fn, attempts = 2, delayMs = 400) {\n",
    "  let lastError;\n",
    "  for (let attempt = 0; attempt <= attempts; attempt += 1) {\n",
    "    try {\n",
    "      return await fn();\n",
    "    } catch (error) {\n",
    "      lastError = error;\n",
    "    }\n",
    "    await new Promise((resolve) => setTimeout(resolve, delayMs));\n",
    "  }\n",
    "  throw lastError;\n",
    "}\n",
    "''')\n",
    "print(\"Retry helper was written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc57ad",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2: Form integration\n",
    "The React form now leans on a reusable `withRetry` helper so network hiccups do not derail the student experience. The flow looks like this:\n",
    "\n",
    "1. Collect user input in local component state.\n",
    "2. Call `withRetry` with an async function that posts the form data.\n",
    "3. Retry the call if a transient failure occurs, backing off briefly between attempts.\n",
    "4. Show a friendly message if every attempt fails, otherwise render the echoed response.\n",
    "\n",
    "```jsx\n",
    "// Flow: collect input -> call withRetry -> update component state with the response\n",
    "const sendEcho = () =>\n",
    "  withRetry(\n",
    "    () => post('/echo', { msg }), // Async callback posting the current message text to FastAPI\n",
    "    2, // Retry up to two extra attempts for transient 5xx or network errors\n",
    "    500, // Wait 500 ms between attempts before trying again\n",
    "  );\n",
    "```\n",
    "\n",
    "Because `withRetry` only depends on an async callback, you can scale the pattern across modules. For example, a profile page could share the helper from `src/lib/retry.js` and dial in its own policy:\n",
    "\n",
    "```jsx\n",
    "// Flow: fetch profile data with the shared retry helper so the page stays resilient\n",
    "const fetchProfile = () =>\n",
    "  withRetry(\n",
    "    () => api.getProfile(userId), // Invoke a module-level API client using the current userId\n",
    "    3, // Allow three total attempts to tolerate slow or flaky upstream services\n",
    "    800, // Back off 800 ms between retries (tweak or expand to exponential backoff as needed)\n",
    "  );\n",
    "```\n",
    "\n",
    "> Tip: pass higher attempt counts and delays when hitting slower services or when layering exponential backoff (`delayMs * attempt`).\n",
    "\n",
    "Larger forms follow the same controlled-input structure: hold each field in state, validate before submitting, and surface field-level errors next to the relevant inputs. When multiple fields need to submit together, build one payload object and reuse `withRetry` so the entire submission benefits from resilience.\n",
    "\n",
    "To see retries in action, the backend now exposes `/flaky-echo`. Point the helper at it during testing:\n",
    "\n",
    "```jsx\n",
    "// Flow: exercise the flaky endpoint to watch retries resolve the request in development\n",
    "await withRetry(\n",
    "  () => post('/flaky-echo?failures=2', { msg }), // Endpoint intentionally fails twice before succeeding\n",
    "  3, // Provide three total attempts so the third call can succeed\n",
    "  500, // Pause half a second between attempts to avoid hammering the server\n",
    ");\n",
    "```\n",
    "\n",
    "The first two requests return HTTP 503 errors, the third succeeds, and the UI recovers gracefully. Wrap longer-lived retry sequences in loading spinners, keep buttons disabled until the promise settles, and consider error boundaries to catch truly fatal issues. These guardrails help the codebase grow while staying aligned with the lab’s resilient frontend architecture.\n",
    "\n",
    "These commented snippets mirror the updates you will apply to `src/App.jsx` (and related hooks) so learners can translate the notebook guidance directly into the working project files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "app_js = Path(\"ai-web/frontend/src/App.jsx\")\n",
    "text = app_js.read_text()\n",
    "if \"withRetry\" not in text:\n",
    "    text = text.replace(\n",
    "        \"import { post } from './lib/api';\",\n",
    "        \"import { post } from './lib/api';\n",
    "import { withRetry } from './lib/retry';\",\n",
    "    )\n",
    "if \"withRetry\" in text and \"withRetry(() => post\" not in text:\n",
    "    text = text.replace(\n",
    "        \"const json = await post('/echo', { msg });\",\n",
    "        \"const json = await withRetry(() => post('/echo', { msg }), 2, 500);\",\n",
    "    )\n",
    "if \"setError(String(err));\" in text:\n",
    "    text = text.replace(\n",
    "        \"setError(String(err));\",\n",
    "        \"setError('A temporary issue was encountered. Please try again.');\",\n",
    "    )\n",
    "app_js.write_text(text)\n",
    "print(\"App.jsx was adjusted for retry and friendly errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9a017e",
   "metadata": {},
   "source": [
    "## Validation / acceptance checks\n",
    "```bash\n",
    "# locally\n",
    "curl -X POST http://localhost:8000/echo -H 'Content-Type: application/json' -d '{\"msg\":\"retry\"}'\n",
    "```\n",
    "- The echoed payload is returned successfully after transient failures are simulated.\n",
    "- React development mode shows the described UI state without console errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74384a",
   "metadata": {},
   "source": [
    "## Homework / extensions\n",
    "- Additional retry backoff strategies are outlined for future reference.\n",
    "- Form validation rules are drafted to prevent empty submissions."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
